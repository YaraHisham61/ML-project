{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9396771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder , StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a5d66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes_012\n",
      "0.0    213703\n",
      "2.0     35346\n",
      "1.0      4631\n",
      "Name: count, dtype: int64\n",
      "Diabetes_012\n",
      "0.0    213703\n",
      "1.0     39977\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "diabetes = pd.read_csv(\"diabetes_012_health_indicators_BRFSS2015.csv\")\n",
    "# print(diabetes['Diabetes_012'].value_counts())\n",
    "# diabetes['Diabetes_012'] = diabetes['Diabetes_012'].replace(2, 1)\n",
    "diabetes.head()\n",
    "# print(diabetes['Diabetes_012'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20cd076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, x_test = train_test_split(diabetes, test_size=0.2, random_state=42)\n",
    "x_test,y_test = x_test.drop(['Diabetes_012'],axis=1),x_test['Diabetes_012']\n",
    "\n",
    "# x_train, x_val = train_test_split(x_train, test_size=0.20, random_state=42)\n",
    "\n",
    "x_train,y_train = x_train.drop(['Diabetes_012'],axis=1),x_train['Diabetes_012']\n",
    "# x_val,y_val = x_val.drop(['Diabetes_012'],axis=1),x_val['Diabetes_012']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a83449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "svm = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', SVC(probability=True,kernel='linear', class_weight='balanced'\n",
    "                  ,random_state=42\n",
    "                    ,C=0.1,gamma='scale',degree=3)\n",
    "                  )\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# grid_search = GridSearchCV(svm, params, cv=5, scoring='accuracy')\n",
    "# 4. Run grid search\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "# 5. Show results\n",
    "# print(\"Best parameters:\", grid_search.best_params_)\n",
    "# print(\"Best cross-validation score: {:.2%}\".format(grid_search.best_score_))\n",
    "\n",
    "# 6. Evaluate on test set\n",
    "# best_model = grid_search.best_estimator_\n",
    "y_pred = svm.predict(x_test)\n",
    "print(\"\\nTest Accuracy: {:.2%}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0ec1c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8434839167455062\n",
      "Diabetes_012\n",
      "0.0    42795\n",
      "1.0     7941\n",
      "Name: count, dtype: int64\n",
      "Diabetes_012\n",
      "0.0    170908\n",
      "1.0     32036\n",
      "Name: count, dtype: int64\n",
      "Counter({np.float64(0.0): 50736})\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('perceptron', Perceptron(\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        alpha=0.1,\n",
    "        penalty='l1',\n",
    "        # 'eta0': 0.1,\n",
    "        early_stopping=True,\n",
    "        ))\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipe.fit(x_train, y_train)\n",
    "# Make predictions on the test set\n",
    "y_pred = pipe.predict(x_test)\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(y_test.value_counts())\n",
    "print(y_train.value_counts())\n",
    "print( Counter(y_pred))\n",
    "# print( Counter(y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e7062a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before SMOTE: {np.float64(0.0): np.int64(170908), np.float64(1.0): np.int64(3687), np.float64(2.0): np.int64(28349)}\n",
      "Starting grid search...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV 1/3] END perceptron__alpha=0.001, perceptron__class_weight=balanced, perceptron__max_iter=1000, perceptron__penalty=l2, smote__sampling_strategy={1: 56969};, score=0.695 total time=   1.1s\n",
      "[CV 2/3] END perceptron__alpha=0.001, perceptron__class_weight=balanced, perceptron__max_iter=1000, perceptron__penalty=l2, smote__sampling_strategy={1: 56969};, score=0.577 total time=   1.1s\n",
      "[CV 3/3] END perceptron__alpha=0.001, perceptron__class_weight=balanced, perceptron__max_iter=1000, perceptron__penalty=l2, smote__sampling_strategy={1: 56969};, score=0.563 total time=   1.5s\n",
      "[CV 1/3] END perceptron__alpha=0.01, perceptron__class_weight=balanced, perceptron__max_iter=1000, perceptron__penalty=l2, smote__sampling_strategy={1: 56969};, score=0.507 total time=   1.0s\n",
      "[CV 2/3] END perceptron__alpha=0.01, perceptron__class_weight=balanced, perceptron__max_iter=1000, perceptron__penalty=l2, smote__sampling_strategy={1: 56969};, score=0.583 total time=   0.8s\n",
      "[CV 3/3] END perceptron__alpha=0.01, perceptron__class_weight=balanced, perceptron__max_iter=1000, perceptron__penalty=l2, smote__sampling_strategy={1: 56969};, score=0.449 total time=   0.7s\n",
      "\n",
      "Best parameters: {'perceptron__alpha': 0.001, 'perceptron__class_weight': 'balanced', 'perceptron__max_iter': 1000, 'perceptron__penalty': 'l2', 'smote__sampling_strategy': {1: 56969}}\n",
      "Best CV accuracy: 61.19%\n",
      "\n",
      "Test Accuracy: 67.73%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.73      0.81     42795\n",
      "         1.0       0.03      0.16      0.05       944\n",
      "         2.0       0.25      0.41      0.31      6997\n",
      "\n",
      "    accuracy                           0.68     50736\n",
      "   macro avg       0.40      0.43      0.39     50736\n",
      "weighted avg       0.80      0.68      0.73     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. FIRST ensure you have the right imports\n",
    "from imblearn.pipeline import Pipeline  # CRITICAL - must use imblearn's Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE(random_state=42)),  # Will only be applied to training folds\n",
    "    ('perceptron', Perceptron(random_state=42))\n",
    "])\n",
    "\n",
    "# 4. Define a simplified parameter grid (to ensure it runs first)\n",
    "param_grid = {\n",
    "    'smote__sampling_strategy': [{1: x} for x in [len(y_train[y_train==0])//3]],  # Start with one value\n",
    "    'perceptron__class_weight': ['balanced'],  # Start simple\n",
    "    'perceptron__penalty': ['l2'],  # Start with basic penalty\n",
    "    'perceptron__alpha': [0.001, 0.01],  # Reduced options\n",
    "    'perceptron__max_iter': [1000]\n",
    "}\n",
    "\n",
    "# 5. Create GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=3,  # Reduced folds for initial test\n",
    "    n_jobs=1,  # Start with single job\n",
    "    verbose=3\n",
    ")\n",
    "\n",
    "# 6. Run grid search\n",
    "print(\"Starting grid search...\")\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# 7. Show results\n",
    "print(\"\\nBest parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV accuracy: {:.2%}\".format(grid_search.best_score_))\n",
    "\n",
    "# 8. Final evaluation\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(x_test)\n",
    "print(\"\\nTest Accuracy: {:.2%}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8966e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 37.89%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "preprocessor = StandardScaler()\n",
    "X_train_scaled = preprocessor.fit_transform(x_train)\n",
    "X_test_scaled = preprocessor.transform(x_test)\n",
    "\n",
    "# Apply SMOTE only to training data\n",
    "smote = SMOTE(sampling_strategy={1: len(y_train[y_train==0])//3})\n",
    "X_res, y_res = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Train Perceptron\n",
    "model = Perceptron(\n",
    "    class_weight={0:1, 1:10, 2:3},\n",
    "    penalty='l1',\n",
    "    alpha=0.1,\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_res, y_res)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(\"\\nTest Accuracy: {:.2%}\".format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print(y_test.value_counts())\n",
    "print(y_train.value_counts())\n",
    "print( Counter(y_pred_train))\n",
    "print( Counter(y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebca516f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted class distribution:\n",
      "Training predictions: Counter({np.float64(1.0): 21611, np.float64(0.0): 17714, np.float64(2.0): 11411})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# For predictions (NumPy arrays)\n",
    "print(\"\\nPredicted class distribution:\")\n",
    "print(\"Training predictions:\", Counter(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81ef629f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVE\\AppData\\Local\\Temp\\ipykernel_25808\\952081348.py:10: DeprecationWarning: Non-integer input passed to bincount. In a future version of NumPy, this will be an error. (Deprecated NumPy 2.1)\n",
      "  print(\"Original class distribution:\", np.bincount(y_train))\n",
      "C:\\Users\\LENOVE\\AppData\\Local\\Temp\\ipykernel_25808\\952081348.py:14: DeprecationWarning: Non-integer input passed to bincount. In a future version of NumPy, this will be an error. (Deprecated NumPy 2.1)\n",
      "  counts = np.bincount(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: [170908   3687  28349]\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best Parameters: {'model__alpha': 0.1, 'model__class_weight': {0: 1, 1: 3, 2: 2}, 'model__max_iter': 1000, 'model__penalty': 'l1', 'smote__sampling_strategy': {np.int64(1): np.int64(7374)}}\n",
      "\n",
      "Test Accuracy: 84.35%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# First, analyze your class distribution\n",
    "print(\"Original class distribution:\", np.bincount(y_train))\n",
    "\n",
    "# Create a safer SMOTE configuration\n",
    "def get_smote_strategy(y):\n",
    "    counts = np.bincount(y)\n",
    "    minority_class = np.argmin(counts)\n",
    "    return {minority_class: min(counts[minority_class]*2, max(counts))}  # At most double minority samples\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('model', Perceptron(random_state=42))\n",
    "])\n",
    "\n",
    "# Safer parameter grid\n",
    "param_grid = {\n",
    "    'model__class_weight': ['balanced', {0:1, 1:3, 2:2}],  # Simplified weights\n",
    "    'model__penalty': ['l1', 'l2'],\n",
    "    'model__alpha': [0.001, 0.01, 0.1],\n",
    "    'model__max_iter': [1000, 2000],\n",
    "    'smote__sampling_strategy': [\n",
    "        'auto',\n",
    "        'minority',\n",
    "        get_smote_strategy(y_train)\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Reduced GridSearchCV configuration\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=3,  # Fewer folds for stability\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    error_score='raise'\n",
    ")\n",
    "\n",
    "try:\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    \n",
    "    # Output results\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    y_pred = grid_search.best_estimator_.predict(x_test)\n",
    "    print(\"\\nTest Accuracy: {:.2%}\".format(accuracy_score(y_test, y_pred)))\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(f\"Error encountered: {e}\")\n",
    "    print(\"Try adjusting the SMOTE sampling strategy or class weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541fbfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVE\\AppData\\Local\\Temp\\ipykernel_25792\\2811015241.py:9: DeprecationWarning: Non-integer input passed to bincount. In a future version of NumPy, this will be an error. (Deprecated NumPy 2.1)\n",
      "  print(\"Original class distribution:\", np.bincount(y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: [170908   3687  28349]\n",
      "\n",
      "Fitting model...\n",
      "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing smote, total=   1.1s\n",
      "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   1.7s\n",
      "\n",
      "Training Results:\n",
      "Accuracy: 0.7643537133396405\n",
      "\n",
      "Test Results:\n",
      "Accuracy: 0.7638757489750867\n",
      "\n",
      "Decision function samples: [[0.2        0.18683718 0.66692839]\n",
      " [0.05340987 0.26582571 0.81404856]\n",
      " [0.2        0.18683718 0.22230946]\n",
      " [0.2        0.18683718 0.10287752]\n",
      " [0.2        0.18683718 1.00100463]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVE\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but Perceptron was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import Perceptron\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "perceptron_params = {\n",
    "    'alpha': 0.01,  # Reduced regularization\n",
    "    'class_weight': {0: 3, 1: 7, 2: 3},  # More aggressive weighting\n",
    "    'max_iter': 10000,  # More iterations\n",
    "    'penalty': 'l1',  # Try L2 instead of L1\n",
    "    'random_state': 42,\n",
    "    'eta0': 0.1,  # Higher learning rate\n",
    "    'early_stopping': True,\n",
    "    'validation_fraction': 0.1\n",
    "}\n",
    "\n",
    "# More balanced SMOTE configuration\n",
    "smote_params = {\n",
    "    'sampling_strategy': {1: 15000, 2: 30000},  # More balanced approach\n",
    "    'random_state': 42,\n",
    "    'k_neighbors': 5\n",
    "}\n",
    "\n",
    "# Create pipeline with verbose output\n",
    "optimized_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE(**smote_params)),\n",
    "    ('classifier', Perceptron(**perceptron_params))\n",
    "], verbose=True)\n",
    "\n",
    "# Fit with validation\n",
    "print(\"\\nFitting model...\")\n",
    "optimized_pipeline.fit(x_train, y_train)\n",
    "\n",
    "# Check resampled class distribution\n",
    "if hasattr(optimized_pipeline.named_steps['smote'], 'sample_indices_'):\n",
    "    print(\"\\nResampled class distribution:\", \n",
    "          np.bincount(optimized_pipeline.named_steps['smote'].sample_indices_))\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = optimized_pipeline.predict(x_train)\n",
    "y_pred_test = optimized_pipeline.predict(x_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nTraining Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
    "# print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "print(\"\\nTest Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "# print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "# Check decision function\n",
    "if hasattr(optimized_pipeline.named_steps['classifier'], 'decision_function'):\n",
    "    print(\"\\nDecision function samples:\", \n",
    "          optimized_pipeline.named_steps['classifier'].decision_function(x_test[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66351870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes_012\n",
      "0.0    42795\n",
      "2.0     6997\n",
      "1.0      944\n",
      "Name: count, dtype: int64\n",
      "Diabetes_012\n",
      "0.0    170908\n",
      "2.0     28349\n",
      "1.0      3687\n",
      "Name: count, dtype: int64\n",
      "Counter({np.float64(1.0): 101966, np.float64(0.0): 99874, np.float64(2.0): 1104})\n",
      "Counter({np.float64(1.0): 25731, np.float64(0.0): 24730, np.float64(2.0): 275})\n"
     ]
    }
   ],
   "source": [
    "print(y_test.value_counts())\n",
    "print(y_train.value_counts())\n",
    "print( Counter(y_pred_train))\n",
    "print( Counter(y_pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
