{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed869266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best features: Index(['HighBP', 'HighChol', 'BMI', 'HeartDiseaseorAttack', 'GenHlth',\n",
      "       'PhysHlth', 'DiffWalk', 'Age', 'Education', 'Income'],\n",
      "      dtype='object')\n",
      "Training Accuracy: 72.23%\n",
      "Test Accuracy: 72.24%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " No Diabetes       0.96      0.72      0.82     40903\n",
      "    Diabetes       0.27      0.77      0.40      5689\n",
      "\n",
      "    accuracy                           0.72     46592\n",
      "   macro avg       0.62      0.74      0.61     46592\n",
      "weighted avg       0.87      0.72      0.77     46592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import  StandardScaler \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "diabetes = pd.read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n",
    "def drop_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    df_cleaned = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df_cleaned\n",
    "\n",
    "diabetes_cleaned = drop_outliers_iqr(diabetes, 'BMI')\n",
    "diabetes_cleaned = drop_outliers_iqr(diabetes_cleaned, 'GenHlth')\n",
    "\n",
    "x_train, x_test = train_test_split(diabetes_cleaned, test_size=0.20, random_state=42)\n",
    "x_test,y_test = x_test.drop(['Diabetes_binary'],axis=1),x_test['Diabetes_binary']\n",
    "x_train,y_train = x_train.drop(['Diabetes_binary'],axis=1),x_train['Diabetes_binary']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(x_train)\n",
    "x_train_scaler = scaler.transform(x_train)\n",
    "x_test_scaler = scaler.transform(x_test)\n",
    "\n",
    "selector = SelectKBest(f_classif, k=10)\n",
    "X_new = selector.fit_transform(x_train, y_train)\n",
    "\n",
    "selected_features = x_train.columns[selector.get_support()]\n",
    "print(\"Best features:\", selected_features)\n",
    "\n",
    "X_train_selected = selector.transform(x_train)\n",
    "X_test_selected = selector.transform(x_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train_selected)\n",
    "x_train_scaler = scaler.transform(X_train_selected)\n",
    "x_test_scaler = scaler.transform(X_test_selected)\n",
    "\n",
    "\n",
    "model = BalancedBaggingClassifier(\n",
    "    estimator=LogisticRegression(),\n",
    "    n_estimators=100,\n",
    "    sampling_strategy='auto',  \n",
    "    replacement=False,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(x_train_scaler, y_train)\n",
    "\n",
    "y_train_pred = model.predict(x_train_scaler)\n",
    "y_test_pred = model.predict(x_test_scaler)\n",
    "\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred) * 100\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred) * 100\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=['No Diabetes', 'Diabetes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea0d08af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 75.77%\n",
      "Test Accuracy: 74.54%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " No Diabetes       0.95      0.75      0.84     40903\n",
      "    Diabetes       0.29      0.73      0.41      5689\n",
      "\n",
      "    accuracy                           0.75     46592\n",
      "   macro avg       0.62      0.74      0.62     46592\n",
      "weighted avg       0.87      0.75      0.79     46592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(\n",
    "    scale_pos_weight=6, \n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(x_train_scaler, y_train)\n",
    "\n",
    "y_train_pred = model.predict(x_train_scaler)\n",
    "y_test_pred = model.predict(x_test_scaler)\n",
    "\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred) * 100\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred) * 100\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=['No Diabetes', 'Diabetes']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
